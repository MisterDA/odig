<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Anycache (anycache.Anycache)</title><link rel="stylesheet" href="../../_odoc-theme/odoc.css"/><meta charset="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div class="content"><header><nav><a href="../index.html">Up</a> – <a href="../index.html">anycache</a> &#x00BB; Anycache</nav><h1>Module <code>Anycache</code></h1><p>Anycache LRU/2Q cache</p><p><em>v0.7.4 — <a href="https://gitlab.com/edwintorok/ocaml-anycache">homepage</a></em></p><p>Consult the <a href="index.html#basics"><span>basics</span></a>, <a href="index.html#examples"><span>examples</span></a>, and <a href="module-type-S/index.html"><span>module documentation</span></a>.</p><h4 id="references"><a href="#references" class="anchor"></a>References</h4><ul><li>T. Johnson and D. Shasha <em><a href="http://www.vldb.org/conf/1994/P439.PDF">2Q: A Low Overhead High Performance Buffer Management Replacement Algorithm</a>, 1994</em></li><li>T. Unagst <em><a href="http://www.tedunangst.com/flak/post/2Q-buffer-cache-algorithm">2Q buffer cache algorithm</a>, 2014</em></li></ul><nav class="toc"><ul><li><a href="#anycache">Anycache</a></li><li><a href="#basics">Basics</a><ul><li><a href="#lrupolicy">Cache replacement policy</a></li></ul></li><li><a href="#examples">Examples</a></li></ul></nav></header><section><header><h2 id="anycache"><a href="#anycache" class="anchor"></a>Anycache</h2></header><div class="spec module-type" id="module-type-Monad"><a href="#module-type-Monad" class="anchor"></a><code><span class="keyword">module</span> <span class="keyword">type</span> <a href="module-type-Monad/index.html">Monad</a> = <span class="keyword">sig</span> ... <span class="keyword">end</span></code></div><div class="spec module-type" id="module-type-S"><a href="#module-type-S" class="anchor"></a><code><span class="keyword">module</span> <span class="keyword">type</span> <a href="module-type-S/index.html">S</a> = <span class="keyword">sig</span> ... <span class="keyword">end</span></code></div><dl><dt class="spec module" id="module-Make"><a href="#module-Make" class="anchor"></a><code><span class="keyword">module</span> <a href="Make/index.html">Make</a> : <span class="keyword">functor</span> (<a href="Make/argument-1-K/index.html">K</a> : <a href="../../ocaml/Stdlib/Map/index.html#module-type-OrderedType">Stdlib.Map.OrderedType</a>) <span>&#45;&gt;</span> <span class="keyword">functor</span> (<a href="Make/argument-2-M/index.html">M</a> : <a href="index.html#module-type-Monad">Monad</a>) <span>&#45;&gt;</span> <a href="index.html#module-type-S">S</a> <span class="keyword">with</span> <span class="keyword">type</span> <a href="Make/index.html#type-key">key</a> = <a href="Make/argument-1-K/index.html#type-t">K.t</a> <span class="keyword">and</span> <span class="keyword">type</span> 'a <a href="Make/index.html#type-deferred">deferred</a> = <span class="type-var">'a</span> <a href="Make/argument-2-M/index.html#type-t">M.t</a></code></dt><dd><p>define a cache with custom key and monad types</p></dd></dl><dl><dt class="spec module" id="module-Direct"><a href="#module-Direct" class="anchor"></a><code><span class="keyword">module</span> <a href="Direct/index.html">Direct</a> : <a href="index.html#module-type-Monad">Monad</a> <span class="keyword">with</span> <span class="keyword">type</span> 'a <a href="module-type-Monad/index.html#type-t">t</a> = (<span class="type-var">'a</span>, exn) <a href="../../result/Result/index.html#type-result">Result.result</a> <span class="keyword">and</span> <span class="keyword">type</span> ('a, 'b) <a href="module-type-Monad/index.html#type-result">result</a> = (<span class="type-var">'a</span>, <span class="type-var">'b</span>) <a href="../../result/Result/index.html#type-result">Result.result</a></code></dt><dd><p>a direct computation that can either succeed or fail</p></dd></dl><div><div class="spec include"><div class="doc"><p>a cache with string keys and <a href="../../result/Result/index.html#type-result"><code>Result.result</code></a> values</p><details open="open"><summary><span class="def"><code><span class="keyword">include</span> <a href="index.html#module-type-S">S</a> <span class="keyword">with</span> <span class="keyword">type</span> <a href="index.html#module-type-S">S</a>.key = string <span class="keyword">and</span> <span class="keyword">type</span> 'a <a href="index.html#module-type-S">S</a>.deferred = (<span class="type-var">'a</span>, exn) <a href="../../result/Result/index.html#type-result">Result.result</a></code></span></summary><dl><dt class="spec type" id="type-key"><a href="#type-key" class="anchor"></a><code><span class="keyword">type</span> key</code><code> = string</code></dt><dt class="spec type" id="type-deferred"><a href="#type-deferred" class="anchor"></a><code><span class="keyword">type</span> 'a deferred</code><code> = (<span class="type-var">'a</span>, exn) <a href="../../result/Result/index.html#type-result">Result.result</a></code></dt><dt class="spec type" id="type-t"><a href="#type-t" class="anchor"></a><code><span class="keyword">type</span> 'a t</code></dt><dd><p>the type for caches storing associating keys of type <code>key</code> with values of type <code>'a</code></p></dd></dl><dl><dt class="spec type" id="type-validator"><a href="#type-validator" class="anchor"></a><code><span class="keyword">type</span> 'a validator</code><code> = (<a href="index.html#type-key">key</a> * <span class="type-var">'a</span> option) <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-deferred">deferred</a></code></dt><dd><p>the type for cache validation callbacks. <code>validate (key,old)</code> is called with <code>old = None</code> if the key is not in the cache yet and has to be computed. It is called with <code>old=Some data</code> if the key is already in the cache. The validator has to decide whether to return the same value or recompute it (perhas because it is expired / no longer fresh).</p></dd></dl><dl><dt class="spec value" id="val-create"><a href="#val-create" class="anchor"></a><code><span class="keyword">val</span> create : int <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-t">t</a></code></dt><dd><p><code>create n</code> creates a LRU/2Q that can hold at most <code>n</code> elements</p></dd></dl><dl><dt class="spec value" id="val-with_cache"><a href="#val-with_cache" class="anchor"></a><code><span class="keyword">val</span> with_cache : <span class="type-var">'a</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> (<a href="index.html#type-key">key</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-deferred">deferred</a>) <span>&#45;&gt;</span> <a href="index.html#type-key">key</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-deferred">deferred</a></code></dt><dd><p><code>with_cache cache f key</code> acts like <code>f key</code>, except it might make fewer calls to <code>f</code> when the <code>key</code> is already in the cache. On successful termination of <code>f key</code> the result is stored in the cache. <code>f key</code> must always return the same value when called with the same key. Cached values never expire, they are only removed if the cache capacity is exceeded, see <a href="index.html#lrupolicy"><span>cache replacement policy</span></a>.</p></dd></dl><dl><dt class="spec value" id="val-with_validator"><a href="#val-with_validator" class="anchor"></a><code><span class="keyword">val</span> with_validator : <span class="type-var">'a</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-validator">validator</a> <span>&#45;&gt;</span> <a href="index.html#type-key">key</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> <a href="index.html#type-deferred">deferred</a></code></dt><dd><p><code>with_validator cache validator key</code> calls <code>validator</code> each time <code>key</code> is accessed. If the <code>key</code> is not in the cache <code>validator (key, None)</code> is called and it should compute the value associated with <code>key</code>. If the <code>key</code> is already in the cache then <code>validator [key, Some value]</code> is called and <code>validator</code> should decide whether the <code>value</code> is still fresh, or if it should be recomputed. The value returned by <code>validator</code> in either case is stored in the <code>cache</code>. <code>validate (key,_)</code> is allowed to return different values when called with the same key again, provided it properly validates the lifetime of old entries. Values are removed from the cache when its capacity is exceeded, see <a href="index.html#lrupolicy"><span>cache replacement policy</span></a>.</p></dd></dl><dl><dt class="spec value" id="val-get"><a href="#val-get" class="anchor"></a><code><span class="keyword">val</span> get : <span class="type-var">'a</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-key">key</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> option <a href="index.html#type-deferred">deferred</a></code></dt><dd><p><code>get cache key</code> retrieves the <code>key</code> from the <code>cache</code> if it exists. The key's position in LRU is updated</p></dd></dl><dl><dt class="spec value" id="val-set"><a href="#val-set" class="anchor"></a><code><span class="keyword">val</span> set : <span class="type-var">'a</span> <a href="index.html#type-t">t</a> <span>&#45;&gt;</span> <a href="index.html#type-key">key</a> <span>&#45;&gt;</span> <span class="type-var">'a</span> <span>&#45;&gt;</span> unit</code></dt><dd><p><code>set cache key value</code> stores <code>value</code> under <code>key</code> in the <code>cache</code>. If a value for <code>key</code> was already stored then it is replaced by the new <code>value</code>. It is not specified whether the key's position is updated in the LRU.</p></dd></dl></details></div></div></div><div class="spec module" id="module-PendingLimit"><a href="#module-PendingLimit" class="anchor"></a><code><span class="keyword">module</span> <a href="PendingLimit/index.html">PendingLimit</a> : <span class="keyword">sig</span> ... <span class="keyword">end</span></code></div></section><section><header><h2 id="basics"><a href="#basics" class="anchor"></a>Basics</h2><p>This module defines a cache that can be used to speed up slow computations (typically involving network or disk I/O). When a computation finishes successfully its result is stored in the cache. If the computation fails only the key is cached, the value is recomputed assuming that errors are transitory.</p><p>If you try to lookup a value in the cache while a computation is in progress (only possible if you are using Lwt or Async) then you get the result from the previous computation if it succeeds (and recomputed on failure). This ensures that you don't flood the disk/network with queries for the same key. Handling timeouts is the caller's responsibility though.</p><p>If the computation is referentially transparent (always returns the same value when invoked with the same key) then <a href="module-type-S/index.html#val-with_cache"><code>Anycache.S.with_cache</code></a> should be used for caching.</p><p>If the computation can return different values when called at different times, and this affects the semantics of your application (e.g. reading a file, performing an http query) then <a href="module-type-S/index.html#val-with_validator"><code>Anycache.S.with_validator</code></a> should be used. It allows to specify a validator that can determine whether the result is still valid, and recompute it if needed (e.g. by performing a conditional HTTP GET).</p><p>The lookup times are worst case logarithmic in the size of the cache. This is needed to avoid the worst case linear lookup times of a hash table in case of collisions (the keys are assumed to be externally controllable, e.g. from a URL or form values). If this overhead is not acceptable or you just want to cache pure computations look at <code>Memo</code> (from <code>core_kernel</code>) or <code>CCCache</code> (from <code>containers</code>) instead.</p><p>A cache with string keys is provided by default, you can instantiate your own using <a href="Make/index.html"><code>Make</code></a>.</p></header><section><header><h3 id="lrupolicy"><a href="#lrupolicy" class="anchor"></a>Cache replacement policy</h3><p>When the cache's capacity is exceeded an old element is removed. The old element is determined such that we keep often accessed values in the cache, and that accessing a long sequence of elements once (a scan) doesn't completely remove all elements from the cache.</p><p>Three queues are used: short-term (<code>A1in</code>), evicted short-term (<code>A1out</code>), and long-term (<code>Amain</code>).</p><p>Elements start out in the short-term cache, and when its capacity is exceeded the element is moved to the evicted short-term queue (we preserve the data). If it is accessed again while on the evicted queue it is promoted to the long-term queue, otherwise when the evicted queue's capacity is exceeded it is dropped. Accessing elements while on the short-term queue has no effect, and it is managed like a FIFO queue.</p><p>When the long-term queue's capacity is exceeded its Least Recently Used element is discarded.</p><p>The short-term queue stores at most 25% of total capacity, and the long-term queue stores at most 50%. The evicted queue's size is dynamically adjusted to use all available space, i.e. when the long-term queue has few elements it will store more than 25% of the elements. This is done so that we always use the cache to its full capacity, even if the long-term elements are few.</p></header></section></section><section><header><h2 id="examples"><a href="#examples" class="anchor"></a>Examples</h2><p>Given a potentially slow function (DNS lookup):</p><pre><code class="ml">open Result
let lookup name =
  Printf.printf &quot;Looking up %s\n&quot; name;
  try Ok (Unix.getaddrinfo name &quot;&quot; [])
  with e -&gt; Error e

let print_result = function
| Ok lst -&gt; Printf.printf &quot;Got %d addresses\n&quot; (List.length lst);
| Error e -&gt; raise e</code></pre><p>We can construct a cached version:</p><pre><code class="ml">let cache = Anycache.create 1024
let cached_lookup = Anycache.with_cache cache lookup

let () =
  print_result (cached_lookup &quot;example.com&quot;);
  print_result (cached_lookup &quot;example.com&quot;);
  print_result (cached_lookup &quot;example.net&quot;);</code></pre><p>Running it produces:</p><pre>$ ocaml $(opam config var anycache:doc)/example.ml
Looking up example.com
Got 6 addresses
Got 6 addresses
Looking up example.net
Got 6 addresses</pre></header></section></div></body></html>